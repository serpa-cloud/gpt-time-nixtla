# GPT Time Nixtla + Vantage by Serpa Cloud

## [About GPT Time](#about)

For tech-driven companies, one of their main challenges is to have proper visibility into the costs generated by tools and cloud infrastructure, as well as the ability to do forecasting to project these costs. With the power of AI, we can achieve accurate predictions to easily make data-driven decisions.

This app provides visibility to engineering teams regarding their costs by using:

- The APIs from [Vantage](https://www.vantage.sh/) to extract data from different accounts and tools.
- The APIs from [Nixtla](https://docs.nixtla.io/) to perform forecasting and predictions based on GPT time series.
- [OpenAI](https://openai.com/) to generate linguistic analysis of the data.

Demo:

[GPT Time Nixtla + Vantage by Serpa Cloud](https://nixtla--nixtla-vantage-webapp--nixtla-web-app.cdn.sierranegra.cloud/)

The project includes a server component to manage the services and a web app based on [React](https://react.dev/).

## [Before Start](#before-start)

Before running this application, you'll need:

- Token/API key from [Vantage](https://www.vantage.sh/)
- Token/API key from [Nixtla](https://docs.nixtla.io/)
- Token/API key from [OpenAI](https://openai.com/)
- [NodeJS](https://nodejs.org/) v16+ installed

## [Getting Started](#getting-started)

After cloning, install dependencies by running

```
yarn
```

### [Running in Development Mode (localhost)](#development-mode)

To run the project, you need to execute both components in parallel:

#### Server

```
export NIXTLA_TOKEN="MY_NIXTLA_TOKEN" && export OPENAI_API_KEY="MY_OPENAI_API_KEY" && yarn serve
```

This runs the backend server at [http://localhost:7001](http://localhost:7001).

#### Client

```
yarn start
```

This runs the web app in development mode. Open [http://localhost:3000](http://localhost:3000) in your browser. The page will reload when you make changes.

### [Running in Live Mode](#live-mode)

#### Compile the Web App

```
yarn build
```

#### Server

```
export NIXTLA_TOKEN="MY_NIXTLA_TOKEN" && export OPENAI_API_KEY="MY_OPENAI_API_KEY" && yarn serve
```

This runs the backend server at [http://localhost:7001](http://localhost:7001) and exposes static files at the root.

### [Build Docker from Source](#docker-from-source)

#### Create the Docker Image

```
docker build --pull --rm -f "Dockerfile" -t gpt-time-nixtla-vantage:latest "."
```

#### Run the Docker Image

```
docker run --env OPENAI_API_KEY="MY_OPENAI_API_KEY" --env NIXTLA_TOKEN="MY_NIXTLA_TOKEN" -p 127.0.0.1:80:80/tcp gpt-time-nixtla-vantage:latest
```

This runs the backend server at [http://localhost](http://localhost) and exposes static files at the root.

### [Running using Docker from Dockerhub](#docker)

#### Run the container

```
docker run --env OPENAI_API_KEY="MY_OPENAI_API_KEY" --env NIXTLA_TOKEN="MY_NIXTLA_TOKEN" -p 127.0.0.1:80:80/tcp serpacloud/gpt-time-nixtla-vantage:latest
```

This runs the backend server at [http://localhost](http://localhost) and exposes static files at the root.

## [Deploy](#deploy)

You can make modifications to this application and easily deploy it using [Serpa Cloud](https://serpa.cloud). Just fork it on GitHub or upload the application to a new repository.

When configuring the deployment, remember to add the environment variables with your API keys, **OPENAI_API_KEY**, and **NIXTLA_TOKEN**.

<img src="https://static.serpa.cloud/6b14af70-3e69-11ee-9672-0f38f31afbc3/640/0/0/serpa-deploy" width="640" />
